<!doctype html>

<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Oscillating Integrals</title>
  <meta name="description" content="Oscillating Integrals">
  <meta name="author" content="James Capers">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
	<style>
		html{margin:0; padding:0; font-family: Palatino, "Palatino Linotype", "Palatino LT STD", "Book Antiqua", Georgia, serif;}
		body{font-size: 14pt; max-width:800px; margin:0 auto; padding:0 25px;}
		header{margin-bottom:3em;}
		h1{text-align: center;}
		h2{font-size:130%}
		h3{font-size:100%}
		li{margin-bottom:0.3em}
		hr{height:3px;border-width:0;color:black;background-color:black}
		a:visited{color: blue;}
	</style>
</head>
<body>
	<a href="../index.html"> Back to homepage </a>, <a href="../blog.html"> Back to blog </a>
	<h1> Oscillating Integrals </h1>

    <h2>&#167 1 A trick</h2>
    Can then integral 
    \begin{equation} 
        I = \int_0^\infty \sin x dx 
    \end{equation}
    be evaluated?
    Let's see what happens if we do a convergence test.  
    We call the upper limit \(\alpha\) and do the integral
    \begin{align} 
        I &= \int_0^\alpha \sin x dx \\
        &= -\left[ \cos x \right]_0^\alpha \\
        &= -\cos \alpha + \cos 0 \\
        &= 1 - \cos \alpha . 
    \end{align}
    Since \(\cos \alpha\) oscillates between -1 and 1 as we send \(\alpha \rightarrow \infty\) the integral can take values between 0 and 2.
    This tells us that the integral does not converge to one value for these limits. <br>
    However, there is a trick we can play that gets used fairly often in theoretical physics to evaluate these kinds of integrals.
    We can re-write the original integral as the limit 
    \begin{equation} 
        I = \lim_{\eta \rightarrow 0} \int_0^\infty e^{-\eta x} \sin x dx ,
    \end{equation}
    where \(\eta > 0\).
    We can see that for \(\eta = 0\) exponential terms becomes 1 and we have our original integral back.
    The benefit of adding this extra part is that it means that the integeral converges since the decaying expoential forces the integrand to go to zero at infinity.
    The integral can now be evaluated by writing \(\sin x\) in terms of complex exponentials  
    \begin{align} 
        I &= \lim_{\eta \rightarrow 0} \frac{1}{2i} \int_0^\infty e^{-\eta x} \left( e^{ix} - e^{-ix} \right) dx , \\
        &= \lim_{\eta \rightarrow 0} \frac{1}{2i} \int_0^\infty \left( e^{-x(\eta - i)}  - e^{-x(\eta + i)} \right) dx . \\
    \end{align}
    This can be integrated easily, giving us 
    \begin{align} 
        I &= \lim_{\eta \rightarrow 0} \frac{1}{2i} \int_0^\infty \left( e^{-x(\eta - i)}  - e^{-x(\eta + i)} \right) dx , \\
        &= \lim_{\eta \rightarrow 0} \frac{1}{2i} \left[ \frac{-1}{\eta - i} e^{-x(\eta - i)}  + \frac{1}{i + \eta} e^{-x(i + \eta)} \right]_0^\infty , \\
        &= \lim_{\eta \rightarrow 0} \frac{1}{2i} \left( \frac{1}{\eta - i} - \frac{1}{i + \eta} \right) .
    \end{align}
    At this point, we take the limit that \(\eta \rightarrow 0\), and are left with 
    \begin{align} 
        I &= \frac{1}{2i} \left( \frac{1}{- i} - \frac{1}{i} \right) \\
        &= \frac{1}{2i} \left( i - (-i) \right) = \frac{2i}{2i} \\
        &= 1 .
    \end{align}
    While this may seem like a trick, this technique is very powerful when it comes to evaluating lots of different types of oscillating integrals that need to be calculated to solve physics problems.

    <h2>&#167 2 Diverging Integrals</h2>

    As another example of this method, let's try to evaluate the explicitly divergent integral
    \begin{equation}  
        I = \int_0^\infty e^x dx . 
    \end{equation}
    It is very clear that as \(x \rightarrow \infty\), \(e^x \rightarrow \infty\).  
    We play the same trick as before, adding a factor that ensures that the integrand vanishes at infinity, giving us
    \begin{align} 
        I &= \lim_{\eta \rightarrow 0} \int_0^\infty e^x e^{-\eta x} dx \\
        &= \lim_{\eta \rightarrow 0} \int_0^\infty e^{-x(\eta - 1)} dx \\
        &= \lim_{\eta \rightarrow 0} \left[ \frac{-1}{\eta - 1} e^{-x(\eta - 1)} \right]_0^\infty \\
        &= \lim_{\eta \rightarrow 0} \frac{1}{\eta - 1} \\
        &= -1 .
    \end{align}

    <h2>&#167 3 The Casimir Effect</h2>

    For an example from physics of why you might want to use this trick, we can think about the <a href="https://en.wikipedia.org/wiki/Casimir_effect">Casimir effect</a>
    If you have two thin metal plates and place them very close together (on the order of microns), they are attracted to each other.
    This is because fewer electromagnetic modes are supported inside the plates than outside, so there is an inwards force as a direct consequence of zero-point energy fluctuations of the electromagnetic field.
    When calculating the Casimir force in 1D, you need to work out the difference between a divergent sum and a divergent integral
    \begin{equation} 
        \Delta E \propto \sum_{\nu = 1}^\infty \nu - \int_0^\infty \nu d\nu = \frac{-1}{12}.
    \end{equation}
    This gives the difference in energy between the inside of the plates and the rest of the universe, which is related to the force that the plates feel.
    It seems odd that the difference between two infinities is -1/12, however we can see how this comes about using our trick!
    Before we dive into the working, it's worth noting that this is not how <a href="https://www.mit.edu/~kardar/research/seminars/Casimir/Casimir1948.pdf">Casimir found the difference</a> and it's not a particularly good way of doing this.
    The proper way to work out the sum-integral difference is using the <a href="https://en.wikipedia.org/wiki/Eulerâ€“Maclaurin_formula">Euler-Maclaurin formula</a>.
    With that said, let's see what we can do using the trick we've been thinking about.
    Let's start with the integral.

    <h3>Evaluating the Integral</h3>

    Just like before, we insert our decaying factor to force convergence
    \begin{equation}  
        I = \int_0^\infty \nu d\nu = \lim_{\eta \rightarrow 0} \int_0^\infty \nu e^{-\eta \nu} d\nu ,
    \end{equation}
    which can be integrated by parts to give us 
    \begin{align}  
        I &= \lim_{\eta \rightarrow 0} \left( \left[ -\frac{\nu e^{-\eta \nu}}{\eta} \right]_0^\infty + \frac{1}{\eta} \int_0^\infty e^{-\eta \nu} d\nu \right) \\
        &= \lim_{\eta \rightarrow 0} \frac{1}{\eta} \int_0^\infty e^{-\eta \nu} d\nu \\
        &= \lim_{\eta \rightarrow 0} -\frac{1}{\eta^2} \left[ e^{-\eta \nu} \right]_0^\infty \\
        &= \lim_{\eta \rightarrow 0} -\frac{1}{\eta^2}(0 - 1) \\
        &= \lim_{\eta \rightarrow 0} \frac{1}{\eta^2} .
    \end{align}
    This doesn't look very encouraging: we've still got something that will diverge when we take the limit.
    Before we jump to any conclusions though, let's see if we can evaluate the sum.  
    This will take some work (so skip to the answer if you're in a hurry).

    <h3>Evaluating the Summation</h3>

    We can use basically the same trick to force the summation to converge as we used for the integrals, but the calculation does involve quite a lot of faffing about.
    Starting in the same way, we write the sum as 
    \begin{equation} 
        S = \lim_{\eta \rightarrow 0} \sum_{\nu = 1}^\infty \nu e^{-\eta \nu} .
    \end{equation}
    We can notice that this can also be written as 
    \begin{align} 
        S &= \lim_{\eta \rightarrow 0} \left( -\frac{\partial}{\partial \eta} \sum_{\nu = 1}^\infty e^{-\eta \nu} \right) , \\
        &= \lim_{\eta \rightarrow 0} \left( -\frac{\partial}{\partial \eta} \sum_{\nu = 1}^\infty \left[ e^{-\eta} \right]^\nu \right) . 
    \end{align}
    Now, if we write \(\nu = p+1\) so that at \(\nu = 1\), \(p = 0\) then the summation becomes
    \begin{equation} 
        S = \lim_{\eta \rightarrow 0} \left( -\frac{\partial}{\partial \eta} \sum_{p = 0}^\infty e^{-\eta} \left( e^{-\eta} \right)^p \right) ,
    \end{equation}
    which is just the geometric series \(\sum_{n=0}^\infty x^n = 1/(1-x)\).
    We now have 
    \begin{equation} 
        S = \lim_{\eta \rightarrow 0} \left( -\frac{\partial}{\partial \eta} \frac{e^{-\eta}}{(1-e^{-\eta})} \right) . 
    \end{equation}
    Evaluating the derivative gives 
    \begin{equation}  
        S = \lim_{\eta \rightarrow 0} \frac{e^{-\eta}}{(1 - e^{-\eta})^2} .
    \end{equation}
    We're slowly getting there!
    Now, it's not too difficult to convince yourself that 
    \begin{equation} 
        \frac{1}{4 \sinh^2 (\eta /2)} = \frac{e^{-\eta}}{(1 - e^{-\eta})^2} . 
    \end{equation}
    Next, we Taylor expand \(\sinh (x)\) around \(x=0\), getting
    \begin{align} 
        \sinh (x) &\approx \sinh (0) + x \cosh (0) + \frac{x^2}{2!} \sinh (0) + + \frac{x^3}{3!} \cosh (0) \\
        &= x + \frac{x^3}{3!} + \ldots
    \end{align}
    Using this, we can write the sum as 
    \begin{align}  
        S &= \lim_{\eta \rightarrow 0} \left[ \frac{1}{4} \left( \sinh \frac{\eta}{2} \right)^{-2} \right] \\
        &= \lim_{\eta \rightarrow 0} \left[ \frac{1}{4} \left( \frac{\eta}{2} + \frac{\eta^3}{48} + \ldots \right)^{-2} \right] \\
        &= \lim_{\eta \rightarrow 0} \left[ \frac{1}{\eta^2} \left( 1 + \frac{\eta^2}{24} + \ldots \right)^{-2} \right]
    \end{align}
    We can finally get rid of the brackets using the binomial expansion \((1+x)^\alpha \approx 1 + \alpha x\), leaving us with just
    \begin{equation}  
        S = \lim_{\eta \rightarrow 0} \left( \frac{1}{\eta^2} - \frac{1}{12}\right) .
    \end{equation}

    <h3>Putting everything together</h3> 

    We can now put together the results for the sum and the integral to find \(\Delta E = \sum_{\nu = 1}^\infty \nu - \int_0^\infty \nu d\nu\).
    We have 
    \begin{align}  	
        \Delta E &= \lim_{\eta \rightarrow 0} \left[ \frac{1}{\eta^2} - \frac{1}{12} - \frac{1}{\eta^2} \right] \\
        &= -\frac{1}{12} .
    \end{align}
    This number, when multiplied by some physical constants, gives the size of the Casimir force between two plates which is somethigng that <a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.78.5">can be measured</a>!
    We should take a minute to think about how weird this is.
    We have an infinite sum, that diverges, and an infinite integral that also diverges and when we take their different using a suspicious looking trick we get a number that can actually be measured.
    While peculiar, -1/12 comes up in other places, for example the <a href="https://www.youtube.com/watch?v=w-I6XTVZXww">sum of all natural numbers</a>.
	
</article>
<footer>
	<br>
	Copyright &#169 James Capers, 2020.
</footer>

</body>
</html>
